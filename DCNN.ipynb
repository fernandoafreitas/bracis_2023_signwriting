{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Resources.DCNN import DCNN\n",
    "from Resources.Utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import random\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras import layers\n",
    "# import tensorflow.compat.v1 as tf\n",
    "# import wandb\n",
    "# import os\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# from wandb.keras import WandbCallback\n",
    "# from Resources.Models import DCNN\n",
    "# from Resources.Utils import Utils\n",
    "# \n",
    "# import uuid\n",
    "# from sklearn import preprocessing\n",
    "# import wandb\n",
    "# from dotenv import load_dotenv\n",
    "# import multiprocessing\n",
    "# import collections\n",
    "# from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'asl'\n",
    "# language = 'germany'\n",
    "# language = 'libras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name_or_path = \"Outputs/tokenizers/DistilBertTokenizerFastSW\")\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 07:06:56.049782: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 214, in generator_py_func\n",
      "    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 227, in _convert\n",
      "    result = np.asarray(value, dtype=dtype, order=\"C\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 218, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n",
      "\n",
      "\n",
      "2023-07-09 07:06:56.061155: W tensorflow/core/framework/op_kernel.cc:1816] INVALID_ARGUMENT: TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, 1, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 214, in generator_py_func\n",
      "    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 227, in _convert\n",
      "    result = np.asarray(value, dtype=dtype, order=\"C\")\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 218, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, 1, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\nTraceback (most recent call last):\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 214, in generator_py_func\n    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 227, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nTypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 218, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 52\u001b[0m\n\u001b[1;32m     49\u001b[0m train_dataset \u001b[39m=\u001b[39m K_train_dataset[i]\n\u001b[1;32m     50\u001b[0m test_dataset \u001b[39m=\u001b[39m K_test_dataset[i]\n\u001b[0;32m---> 52\u001b[0m train_dataset, test_dataset \u001b[39m=\u001b[39m iteracoesDataset(train_dataset, test_dataset, data, tokenizer,c)\n\u001b[1;32m     53\u001b[0m VOCAB_SIZE \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(tokenizer\u001b[39m.\u001b[39mvocab)\n\u001b[1;32m     55\u001b[0m NB_CLASSES \u001b[39m=\u001b[39m num_labels\n",
      "File \u001b[0;32m~/Documentos/dr/code/bracis_2023_signwriting/Resources/Utils.py:87\u001b[0m, in \u001b[0;36mUtils.iteracoesDataset\u001b[0;34m(self, train_dataset, test_dataset, data, tokenizer, c)\u001b[0m\n\u001b[1;32m     82\u001b[0m train_tf \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(\u001b[39mlambda\u001b[39;00m: train_sorted_all,\n\u001b[1;32m     83\u001b[0m                                         output_types\u001b[39m=\u001b[39m(tf\u001b[39m.\u001b[39mint32, tf\u001b[39m.\u001b[39mint32))\n\u001b[1;32m     85\u001b[0m test_tf \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_generator(\u001b[39mlambda\u001b[39;00m: test_sorted_all,\n\u001b[1;32m     86\u001b[0m                                         output_types\u001b[39m=\u001b[39m(tf\u001b[39m.\u001b[39mint32, tf\u001b[39m.\u001b[39mint32))\n\u001b[0;32m---> 87\u001b[0m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(train_tf))\n\u001b[1;32m     88\u001b[0m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(test_tf))\n\u001b[1;32m     90\u001b[0m train_tf \u001b[39m=\u001b[39m train_tf\u001b[39m.\u001b[39mpadded_batch(\n\u001b[1;32m     91\u001b[0m     c[\u001b[39m'\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m'\u001b[39m], padded_shapes\u001b[39m=\u001b[39m((\u001b[39mNone\u001b[39;00m, ), ()))\n",
      "File \u001b[0;32m~/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:814\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    813\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 814\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[1;32m    815\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[1;32m    816\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/iterator_ops.py:777\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[0;32m--> 777\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[1;32m    778\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[1;32m    779\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[1;32m    780\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[1;32m    782\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3028\u001b[0m, in \u001b[0;36miterator_get_next\u001b[0;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3027\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3028\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[1;32m   3029\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[1;32m   3030\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\nTraceback (most recent call last):\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 214, in generator_py_func\n    script_ops.FuncRegistry._convert(  # pylint: disable=protected-access\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 227, in _convert\n    result = np.asarray(value, dtype=dtype, order=\"C\")\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\nTypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/ops/script_ops.py\", line 268, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/home/fernando/anaconda3/envs/bracis/lib/python3.11/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 218, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that could not be converted to the expected type. The expected type was int32, but the yielded element was [0, None, None, None, None, 14, None, 14, None, 14, None, None, None, 14].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "sweep_id =  '{}-{}'.format(date,str(uuid.uuid1()))\n",
    "u = Utils()\n",
    "clean_tweet = u.clean_tweet\n",
    "encode_sentence = u.encode_sentence\n",
    "iteracoesDataset = u.iteracoesDataset\n",
    "\n",
    "c = {'EMB_DIM': 512,\n",
    "    'PADDING': 'same',\n",
    "    'dataset': 'details',\n",
    "    'FFN_UNITS': 512,\n",
    "    'NB_EPOCHS': 200,\n",
    "    'size_desc': 4,\n",
    "    'NB_FILTERS': 150,\n",
    "    'batch_size': 32,\n",
    "    'repet_test': 6,\n",
    "    'repet_train': 10-1,\n",
    "    'DROPOUT_RATE': 0.1}\n",
    "k = 10\n",
    "\n",
    "\n",
    "sweep_id =  '{}{}-{}-{}'.format(language,k,date,str(uuid.uuid1()).split('-')[0])\n",
    "# Carrega o dataset\n",
    "data = u.load_db(language, c['dataset'])\n",
    "# seleciona a subamostragem desejada\n",
    "data = u.selectSubGroupDatabase(data, c['repet_train'])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(data.sentence, data.label)\n",
    "\n",
    "K_test_dataset = []\n",
    "K_train_dataset = []\n",
    "\n",
    "for train_index, test_index in skf.split(data.sentence, data.label):\n",
    "    K_train_dataset.append(data.iloc[train_index])\n",
    "    K_test_dataset.append(data.iloc[test_index])\n",
    "    num_labels = len(data.label.unique())\n",
    "\n",
    "for i in range(len(K_train_dataset)):\n",
    "    run_name = \"{}-{}\".format(language, i)\n",
    "    # run = wandb.init(project=\"kfold-bert\", group=sweep_id, name=run_name, job_type = language, config=c)\n",
    "\n",
    "    callbacks = []\n",
    "    callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3))\n",
    "\n",
    "    # callbacks.append(WandbCallback())\n",
    "\n",
    "    train_dataset = K_train_dataset[i]\n",
    "    test_dataset = K_test_dataset[i]\n",
    "\n",
    "    train_dataset, test_dataset = iteracoesDataset(train_dataset, test_dataset, data, tokenizer,c)\n",
    "    VOCAB_SIZE = len(tokenizer.vocab)\n",
    "\n",
    "    NB_CLASSES = num_labels\n",
    "\n",
    "    Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
    "                emb_dim=c['EMB_DIM'],\n",
    "                nb_filters=c['NB_FILTERS'],\n",
    "                FFN_units=c['FFN_UNITS'],\n",
    "                nb_classes=NB_CLASSES,\n",
    "                dropout_rate=c['DROPOUT_RATE'],\n",
    "                padding=c['PADDING'])\n",
    "\n",
    "    Dcnn.compile(loss='sparse_categorical_crossentropy',\n",
    "                optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "    checkpoint_path = 'temp'\n",
    "    ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
    "    ckpt_manager = tf.train.CheckpointManager(\n",
    "        ckpt, checkpoint_path, max_to_keep=1)\n",
    "\n",
    "    history = Dcnn.fit(train_dataset,\n",
    "                    epochs=c['NB_EPOCHS'],\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "    results = Dcnn.evaluate(test_dataset)\n",
    "\n",
    "    top_pred_ids = Dcnn.predict(test_dataset)\n",
    "\n",
    "    r_predict = []\n",
    "    for item in top_pred_ids:\n",
    "        r_predict.append(u.get_prediction(item))\n",
    "\n",
    "    ground_truth_ids = []\n",
    "    for element in test_dataset.as_numpy_iterator():\n",
    "        aux = element[1]\n",
    "        for item in aux:\n",
    "            ground_truth_ids.append(item)\n",
    "\n",
    "    # try:\n",
    "    #     # run.log({\"{}\".format(run_name) : wandb.plot.confusion_matrix(\n",
    "    #                 # preds=r_predict, y_true=ground_truth_ids,\n",
    "    #                 # class_names=le.inverse_transform(ground_truth_ids))})\n",
    "    # except:\n",
    "    #     print(\"Erro no passo {}\".format(run_name))\n",
    "\n",
    "    print({'test_loss': results[0], 'test_sparse_categorical_accuracy': results[1]})\n",
    "    # run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bracis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
