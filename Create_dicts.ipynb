{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1tadN4hSCP9p"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EUU4TlmoFMZ_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import re"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bibliotecas locais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from Resources import Categorize"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "j6ZbE2lPDIFL"
      },
      "source": [
        "## Etapa 2: Carregando o dicionário"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BlackList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def testStrings(string):\n",
        "    string = string.lower()\n",
        "    if(string != 'SIL2007'.lower()\n",
        "       and string != 'SIL 2007'.lower()\n",
        "       and string != 'SIL 2009'.lower()\n",
        "       and string != 'SIL2009'.lower()\n",
        "       and string != 'sil2009'.lower()\n",
        "       and string != 'SIL'.lower()\n",
        "       and string != 'page number'.lower()\n",
        "       and string != 'number'.lower()\n",
        "       and string != 'MEL SC GRUPO'.lower()\n",
        "       and string != 'Daniel'.lower()\n",
        "       and string != 'mel sc sinais proprios'.lower()\n",
        "       and string != 'meu sinal'.lower()\n",
        "       and string != 'MEL SC NT'.lower()\n",
        "       and string != 'MEL SC NOVOS SINAIS'.lower()\n",
        "       and string != 'MEL SC SINAIS PRÓPRIOS'.lower()\n",
        "       and string != 'MEL SC  VT'.lower()\n",
        "       and string != 'MEL SC GLOSSÁRIO'.lower()\n",
        "       and string != 'MEL SC '.lower()\n",
        "       and string != 'MEL SC'.lower()\n",
        "       and string != 'MEL SC PERSONAGENS BÍBLICOS'.lower()\n",
        "       and string != 'Kontakt_Symbol'.lower()\n",
        "       and string != 'Symbol_Proportionen'.lower()\n",
        "       and string != 'é'.lower()\n",
        "       and string != 'É'.lower()\n",
        "       and string != 'cm'.lower()\n",
        "       and string != 'EAL SC'.lower()\n",
        "       and string != 'Marcos'.lower()\n",
        "       and string != 'Gabriel'.lower()\n",
        "       and string != 'rodrigo'.lower()\n",
        "       and string != 'Gisele'.lower()\n",
        "       and string != 'leticia'.lower()\n",
        "       and string != 'maria'.lower()\n",
        "       and string != 'nome'.lower()\n",
        "       and string != 'Aline'.lower()\n",
        "       and string != 'Maria'.lower()\n",
        "       and string != 'pedro'.lower()\n",
        "       and string != 'lucas'.lower()\n",
        "       and string != 'escrita de sinais'.lower()\n",
        "       and string != 'sinal'.lower()\n",
        "       and string != 'ana'.lower()\n",
        "       and string != ' '.lower()\n",
        "       and string != 'marco'.lower()\n",
        "       and string != 'teste'.lower()\n",
        "       and string != 'libras'.lower()\n",
        "       and string != 'Jay'.lower()\n",
        "       and string != 'Kontakt Symbol'.lower()\n",
        "       and string != 'pantomimische Darstellung'.lower()\n",
        "       and string != 'Gedankenpause'.lower()\n",
        "       and string != 'PAM'.lower()\n",
        "       and string != 'name sign A'.lower()\n",
        "       and string != 'name sign AB'.lower()\n",
        "       and string != 'name sign B'.lower()\n",
        "       and string != 'name sign C R'.lower()\n",
        "       and string != 'name sign CF'.lower()\n",
        "       and string != 'name sign CW'.lower()\n",
        "       and string != 'name sign D'.lower()\n",
        "       and string != 'name sign E'.lower()\n",
        "       and string != 'name sign F'.lower()\n",
        "       and string != 'name sign J'.lower()\n",
        "       and string != 'name sign K'.lower()\n",
        "       and string != 'name sign M'.lower()\n",
        "       and string != 'name sign P'.lower()\n",
        "       and string != 'name sign S'.lower()\n",
        "       and string != 'name sign T'.lower()\n",
        "       and string != 'name sign V'.lower()\n",
        "       and string != 'name sign W'.lower()\n",
        "       and string != 'V sign name'.lower()\n",
        "       and string != 'pronoun'.lower()\n",
        "       ):\n",
        "        return True\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Rotina"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Carrega dicionario e chama a função"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dicts(language, type):\n",
        "    tree = ET.parse('Dicts/{}.spml'.format(language))\n",
        "    root = tree.getroot()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Criando o array com os dados brutos"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vocabulário artifical com todas as possibilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vocab = r'(S[123][0-9a-f]{2}[0-5][0-9a-f])'\n",
        "# x = list(exrex.generate(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "fsw_model = r'((A(S[123][0-9a-f]{2}[0-5][0-9a-f])+)|S[0-9a-fA-F]{3}[0-5]{1}[0-9a-fA-F]{1}[0-9]{3}x[0-9]{3})|([BLMR][0-9]{3}x[0-9]{3})|(S[0-9a-fA-F]{3}[0-5]{1}[0-9a-fA-F]{1})'\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Vocabulários Slim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def slim(language):\n",
        "    \n",
        "    tree = ET.parse('Dicts/{}.spml'.format(language))\n",
        "    root = tree.getroot()\n",
        "        \n",
        "    palavras = []\n",
        "    txt_file = 'Outputs/Dicts/{}_raw_slim.txt'.format(language)\n",
        "    raw = open(txt_file, 'w')\n",
        "\n",
        "    for item in root:\n",
        "        if(item.tag == 'entry'):\n",
        "            glosas = []\n",
        "            for subitem in item:\n",
        "                if(subitem.tag == 'term'):\n",
        "                    if(re.match(fsw_model, subitem.text)):\n",
        "                        cod = subitem.text\n",
        "                    else:\n",
        "                        if(testStrings(subitem.text)):\n",
        "                            glosas.append(Categorize.clean_text(subitem.text))\n",
        "            if (len(glosas) > 0 and len(cod) > 0):\n",
        "                palavras.append(glosas)\n",
        "                for g in glosas:\n",
        "                    detalhe = Categorize.details(cod)\n",
        "                    combined = \"\"\n",
        "                    for det in detalhe:\n",
        "                        combined += \"{:} \".format(det['full'])\n",
        "\n",
        "                    if(det['base'] != 'punctuation'):\n",
        "                        raw.write('{}&{}'.format(g, combined))\n",
        "                        raw.write('\\n')\n",
        "    raw.close()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modificação Alfa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def alfa(language):\n",
        "\n",
        "    tree = ET.parse('Dicts/{}.spml'.format(language))\n",
        "    root = tree.getroot()\n",
        "\n",
        "    txt_file = 'Outputs/Dicts/{}_raw_alfa.txt'.format(language)\n",
        "    raw = open(txt_file, 'w')\n",
        "    for item in root:\n",
        "        if(item.tag == 'entry'):\n",
        "            glosas = []\n",
        "            for subitem in item:\n",
        "                if(subitem.tag == 'term'):\n",
        "                    if(re.match(fsw_model, subitem.text)):\n",
        "                        cod = subitem.text\n",
        "                    else:\n",
        "                        if(testStrings(subitem.text)):\n",
        "                            glosas.append(Categorize.clean_text(subitem.text))\n",
        "            if (len(glosas) > 0 and len(cod) > 0):\n",
        "                for g in glosas:\n",
        "                    detalhe = Categorize.details(cod)\n",
        "                    combined = \"\"\n",
        "                    left = 0\n",
        "                    right = 0\n",
        "                    count_right = 0\n",
        "                    count_left = 0\n",
        "                    base_right = None\n",
        "                    base_left = None\n",
        "\n",
        "                    for det in detalhe:\n",
        "                        lr = det['left_right'] if det['left_right'] else ''\n",
        "                        combined += \"{:} {:} {:} {:}. \".format(\n",
        "                            det['N0'], lr, det['base'], det['full'])\n",
        "\n",
        "                        if (base_right != det['base'] and det['N0'] == 'hand' and det['left_right'] == 'right'):\n",
        "                            count_right += 1\n",
        "                        if (base_left != det['base'] and det['N0'] == 'hand' and det['left_right'] == 'left'):\n",
        "                            count_left += 1\n",
        "\n",
        "                        if (det['N0'] == 'hand' and det['left_right'] == 'right'):\n",
        "                            right = 1\n",
        "                            base_right = det['base']\n",
        "\n",
        "                        if (det['N0'] == 'hand' and det['left_right'] == 'left'):\n",
        "                            left = 1\n",
        "                            base_left = det['base']\n",
        "                    combined += \"estaticidadeR{:}. \".format(\n",
        "                        str(True if (count_right < 2) else False))\n",
        "                    combined += \"estaticidadeL{:}. \".format(\n",
        "                        str(True if (count_left < 2) else False))\n",
        "                    combined += \"hands_qtd{:}. \".format(str(right+left))\n",
        "\n",
        "                    if(det['base'] != 'punctuation'):\n",
        "                        raw.write('{}&{}'.format(g, combined))\n",
        "                        raw.write('\\n')\n",
        "    raw.close()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Detalhado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def details(language):\n",
        "    tree = ET.parse('Dicts/{}.spml'.format(language))\n",
        "    root = tree.getroot()\n",
        "\n",
        "    txt_file = 'Outputs/Dicts/{}_raw_details.txt'.format(language)\n",
        "    raw = open(txt_file, 'w')\n",
        "    for item in root:\n",
        "        if(item.tag == 'entry'):\n",
        "            glosas = []\n",
        "            for subitem in item:\n",
        "                if(subitem.tag == 'term'):\n",
        "                    if(re.match(fsw_model, subitem.text)):\n",
        "                        cod = subitem.text\n",
        "                    else:\n",
        "                        if(testStrings(subitem.text)):\n",
        "                            glosas.append(Categorize.clean_text(subitem.text))\n",
        "            if (len(glosas) > 0 and len(cod) > 0):\n",
        "                for g in glosas:\n",
        "                    detalhe = Categorize.details(cod)\n",
        "                    combined = \"\"\n",
        "                    left = 0\n",
        "                    right = 0\n",
        "                    count_right = 0\n",
        "                    count_left = 0\n",
        "                    base_right = None\n",
        "                    base_left = None\n",
        "\n",
        "                    for det in detalhe:\n",
        "                        lr = det['left_right'] if det['left_right'] else ''\n",
        "                        combined += \"{:} {:} {:} {:}{:} {:}. \".format(\n",
        "                            det['N0'], lr, det['base'], det['base'], det['N2'], det['full'])\n",
        "\n",
        "                        if (base_right != det['base'] and det['N0'] == 'hand' and det['left_right'] == 'right'):\n",
        "                            count_right += 1\n",
        "                        if (base_left != det['base'] and det['N0'] == 'hand' and det['left_right'] == 'left'):\n",
        "                            count_left += 1\n",
        "\n",
        "                        if (det['N0'] == 'hand' and det['left_right'] == 'right'):\n",
        "                            right = 1\n",
        "                            base_right = det['base']\n",
        "\n",
        "                        if (det['N0'] == 'hand' and det['left_right'] == 'left'):\n",
        "                            left = 1\n",
        "                            base_left = det['base']\n",
        "                    combined += \"estaticidadeR{:}. \".format(\n",
        "                        str(True if (count_right < 2) else False))\n",
        "                    combined += \"estaticidadeL{:}. \".format(\n",
        "                        str(True if (count_left < 2) else False))\n",
        "                    combined += \"hands_qtd{:}. \".format(str(right+left))\n",
        "\n",
        "                    if(det['base'] != 'punctuation'):\n",
        "                        raw.write('{}&{}'.format(g, combined))\n",
        "                        raw.write('\\n')\n",
        "    raw.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "dicts = ['asl','germany','libras']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "for language in dicts:\n",
        "    slim(language)\n",
        "    alfa(language)\n",
        "    details(language)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Classificação de Sentimentos com BERT e Embedding",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 ('ambvir')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "093884822d76bd3db81bd947c9b66e6f2affc55990b9d5a126829adf59e90f43"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
